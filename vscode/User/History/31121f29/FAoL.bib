
% Dynamic programming
@article{bellman1954theory,
  title={The theory of dynamic programming},
  author={Bellman, Richard},
  journal={Bulletin of the American Mathematical Society},
  volume={60},
  number={6},
  pages={503--515},
  year={1954}
}

% Policy Iteration
@article{howard1960dynamic,
  title={Dynamic programming and markov processes.},
  author={Howard, Ronald A},
  year={1960},
  publisher={John Wiley}
}

% Temporal difference
@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

% Q-Learning
@article{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby and others},
  year={1989},
  publisher={King's College, Cambridge United Kingdom}
}

% REINFORCE
@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

% SARSA
@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994},
  publisher={University of Cambridge, Department of Engineering Cambridge, UK}
}

%NAC
@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

%A2C
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PmLR}
}

%PPO
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

% TD3
@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%             BACKGROUND             %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% MDP
@article{bellman1957markovian,
  title={A Markovian decision process},
  author={Bellman, Richard},
  journal={Journal of mathematics and mechanics},
  pages={679--684},
  year={1957},
  publisher={JSTOR}
}

% Neural networks generalisation study
@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}


%%% RL Classes

% Sarsa
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

% DQN
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{kempka2016vizdoom,
  title        = {Vizdoom: A doom-based ai research platform for visual reinforcement learning},
  author       = {Kempka, Micha{\l} and Wydmuch, Marek and Runc, Grzegorz and Toczek, Jakub and Ja{\'s}kowski, Wojciech},
  booktitle    = {2016 IEEE conference on computational intelligence and games (CIG)},
  pages        = {1--8},
  year         = {2016},
  organization = {IEEE}
}

% Goal-conditioned RL
@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  volume={2},
  pages={1094--8},
  year={1993},
  organization={Citeseer}
}

@article{kimura2002reinforcement,
  title={Reinforcement learning of walking behavior for a four-legged robot},
  author={Kimura, Hajime and Yamashita, Toru and Kobayashi, Shigenobu},
  journal={IEEJ Transactions on Electronics, Information and Systems},
  volume={122},
  number={3},
  pages={330--337},
  year={2002},
  publisher={The Institute of Electrical Engineers of Japan}
}

@inproceedings{randlov1998learning,
  title={Learning to Drive a Bicycle Using Reinforcement Learning and Shaping.},
  author={Randl{\o}v, Jette and Alstr{\o}m, Preben},
  booktitle={ICML},
  volume={98},
  pages={ --471},
  year={1998},
  organization={Citeseer}
}

% AlphaGo
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

% AlphaGoZero
@article{silver2017masteringgo,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

% AlphaZero
@article{silver2017masteringchessandgo,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%        GCRL         %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%   RL APPLICATIONS   %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%

% RL sur starcraft 2
@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

% RL sur dota 2
@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

% Plasma control
@article{degrave2022magnetic,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de Las Casas, Diego and others},
  journal={Nature},
  volume={602},
  number={7897},
  pages={414--419},
  year={2022},
  publisher={Nature Publishing Group}
}

% rl in smart grids
@article{zhang2018review,
  title={Review on the research and practice of deep learning and reinforcement learning in smart grids},
  author={Zhang, Dongxia and Han, Xiaoqing and Deng, Chunyu},
  journal={CSEE Journal of Power and Energy Systems},
  volume={4},
  number={3},
  pages={362--370},
  year={2018},
  publisher={CSEE}
}

% RL for energy management
@article{yu2021review,
  title={A review of deep reinforcement learning for smart building energy management},
  author={Yu, Liang and Qin, Shuqi and Zhang, Meng and Shen, Chao and Jiang, Tao and Guan, Xiaohong},
  journal={IEEE Internet of Things Journal},
  volume={8},
  number={15},
  pages={12046--12063},
  year={2021},
  publisher={IEEE}
}

% Space control revue
@article{tipaldi2022reinforcement,
  title={Reinforcement learning in spacecraft control applications: Advances, prospects, and challenges},
  author={Tipaldi, Massimo and Iervolino, Raffaele and Massenio, Paolo Roberto},
  journal={Annual Reviews in Control},
  volume={54},
  pages={1--23},
  year={2022},
  publisher={Elsevier}
}

% Resources management
@inproceedings{mao2016resource,
  title={Resource management with deep reinforcement learning},
  author={Mao, Hongzi and Alizadeh, Mohammad and Menache, Ishai and Kandula, Srikanth},
  booktitle={Proceedings of the 15th ACM workshop on hot topics in networks},
  pages={50--56},
  year={2016}
}

% Financial portfolio management
@article{jiang2017deep,
  title={A deep reinforcement learning framework for the financial portfolio management problem},
  author={Jiang, Zhengyao and Xu, Dixing and Liang, Jinjun},
  journal={arXiv preprint arXiv:1706.10059},
  year={2017}
}

% Algorithmic traiding
@article{theate2021application,
  title={An application of deep reinforcement learning to algorithmic trading},
  author={Th{\'e}ate, Thibaut and Ernst, Damien},
  journal={Expert Systems with Applications},
  volume={173},
  pages={114632},
  year={2021},
  publisher={Elsevier}
}

% Fraud detection
@inproceedings{el2017fraud,
  title={Fraud detection in banking using deep reinforcement learning},
  author={El Bouchti, Abdelali and Chakroun, Ahmed and Abbar, Hassan and Okar, Chafik},
  booktitle={2017 Seventh International Conference on Innovative Computing Technology (INTECH)},
  pages={58--63},
  year={2017},
  organization={IEEE}
}

% Healthcare applications
@article{yu2021reinforcement,
  title={Reinforcement learning in healthcare: A survey},
  author={Yu, Chao and Liu, Jiming and Nemati, Shamim and Yin, Guosheng},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={1},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY}
}

% Survey on RL for autonomous driving
@article{kiran2021deep,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={6},
  pages={4909--4926},
  year={2021},
  publisher={IEEE}
}

% DDPG
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, TP},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

% SAC
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

% Munchausen DQN
@article{vieillard2020munchausen,
  title={Munchausen reinforcement learning},
  author={Vieillard, Nino and Pietquin, Olivier and Geist, Matthieu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4235--4246},
  year={2020}
}

% Go-Explore
@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

% UVFA
@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

% HER
@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% Dijikstra
@article{dijkstra1959note,
  title={A note on two problems in connexion with graphs},
  author={Dijkstra, Edsger W},
  journal={Numerische mathematik},
  volume={1},
  number={1},
  pages={269--271},
  year={1959}
}

@inproceedings{chaplot2020neural,
  title={Neural topological slam for visual navigation},
  author={Chaplot, Devendra Singh and Salakhutdinov, Ruslan and Gupta, Abhinav and Gupta, Saurabh},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12875--12884},
  year={2020}
}

@article{aubret2021distop,
  title={DisTop: Discovering a Topological representation to learn diverse and rewarding skills},
  author={Aubret, Arthur and Hassas, Salima and others},
  journal={arXiv preprint arXiv:2106.03853},
  year={2021}
}

% SPTM
@inproceedings{savinov2018semi,
  title={Semi-parametric topological memory for navigation},
  author={Savinov, Nikolay and Dosovitskiy, Alexey and Koltun, Vladlen},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

% SORB
@article{eysenbach2019search,
  title={Search on the replay buffer: Bridging planning and reinforcement learning},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.05253},
  year={2019}
}

@article{huang2019mapping,
  title={Mapping state space using landmarks for universal goal reaching},
  author={Huang, Zhiao and Liu, Fangchen and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

% SGM
@article{emmons2020sparse,
  title={Sparse graphical memory for robust planning},
  author={Emmons, Scott and Jain, Ajay and Laskin, Misha and Kurutach, Thanard and Abbeel, Pieter and Pathak, Deepak},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5251--5262},
  year={2020}
}

% STC
@article{ruan2022target,
  title={A target-driven visual navigation method based on intrinsic motivation exploration and space topological cognition},
  author={Ruan, Xiaogang and Li, Peng and Zhu, Xiaoqing and Liu, Pengfei},
  journal={Scientific Reports},
  volume={12},
  number={1},
  pages={1--22},
  year={2022},
  publisher={Nature Publishing Group}
}

% HRL
@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% HIRO
@article{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

% HAC
@inproceedings{levy2019learning,
  title={Learning multi-level hierarchies with hindsight},
  author={Levy, Andrew and Konidaris, George and Platt, Robert and Saenko, Kate},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

% Skew-FIt: uniform state-space exploration
@article{pong2019skew,
  title={Skew-fit: State-covering self-supervised reinforcement learning},
  author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  journal={arXiv preprint arXiv:1903.03698},
  year={2019}
}

% HACx
@article{mcclinton2021hac,
  title={HAC Explore: Accelerating Exploration with Hierarchical Reinforcement Learning},
  author={McClinton, Willie and Levy, Andrew and Konidaris, George},
  journal={arXiv preprint arXiv:2108.05872},
  year={2021}
}

@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr H and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1911.08453},
  year={2019}
}

@article{parascandolo2020divide,
  title={Divide-and-conquer monte carlo tree search for goal-directed planning},
  author={Parascandolo, Giambattista and Buesing, Lars and Merel, Josh and Hasenclever, Leonard and Aslanides, John and Hamrick, Jessica B and Heess, Nicolas and Neitz, Alexander and Weber, Theophane},
  journal={arXiv preprint arXiv:2004.11410},
  year={2020}
}

@inproceedings{strehl2006pac,
  title={PAC model-free reinforcement learning},
  author={Strehl, Alexander L and Li, Lihong and Wiewiora, Eric and Langford, John and Littman, Michael L},
  booktitle={International Conference on Machine learning},
  pages={881--888},
  year={2006}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{silver2017predictron,
  title={The predictron: End-to-end learning and planning},
  author={Silver, David and Hasselt, Hado and Hessel, Matteo and Schaul, Tom and Guez, Arthur and Harley, Tim and Dulac-Arnold, Gabriel and Reichert, David and Rabinowitz, Neil and Barreto, Andre and others},
  booktitle={International Conference on Machine Learning},
  pages={3191--3199},
  year={2017},
  organization={PMLR}
}

@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}

@article{konidaris2009skill,
  title={Skill discovery in continuous reinforcement learning domains using skill chaining},
  author={Konidaris, George and Barto, Andrew},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@inproceedings{badia2019never,
  title={Never Give Up: Learning Directed Exploration Strategies},
  author={Badia, Adri{\`a} Puigdom{\`e}nech and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Piot, Bilal and Kapturowski, Steven and Tieleman, Olivier and Arjovsky, Martin and Pritzel, Alexander and Bolt, Andrew and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{burda2019exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{domingues2021density,
  title={Density-Based Bonuses on Learned Representations for Reward-Free Exploration in Deep Reinforcement Learning},
  author={Domingues, Omar Darwiche and Tallec, Corentin and Munos, Remi and Valko, Michal},
  booktitle={ICML Workshop on Unsupervised Reinforcement Learning},
  year={2021}
}

@article{barto1983neuronlike,
  title={Neuronlike adaptive elements that can solve difficult learning control problems},
  author={Barto, Andrew G and Sutton, Richard S and Anderson, Charles W},
  journal={IEEE transactions on systems, man, and cybernetics},
  volume={13},
  number={5},
  pages={834--846},
  year={1983},
  publisher={IEEE}
}

@book{precup2000temporal,
  title={Temporal abstraction in reinforcement learning},
  author={Precup, Doina},
  year={2000},
  publisher={University of Massachusetts Amherst}
}

@inproceedings{hafner2021mastering,
  title={Mastering Atari with Discrete World Models},
  author={Hafner, Danijar and Lillicrap, Timothy P and Norouzi, Mohammad and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{hafner2020dream,
  title={Dream to Control: Learning Behaviors by Latent Imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

% Mujoco
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

% DADS
@article{sharma2019dynamics,
  title={Dynamics-aware unsupervised discovery of skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  journal={arXiv preprint arXiv:1907.01657},
  year={2019}
}

% Option
@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

% DSG
@inproceedings{bagaria2021skill,
  title={Skill discovery for exploration and planning using deep skill graphs},
  author={Bagaria, Akhil and Senthil, Jason K and Konidaris, George},
  booktitle={International Conference on Machine Learning},
  pages={521--531},
  year={2021},
  organization={PMLR}
}

% Re-usable options
@inproceedings{konidaris2007building,
  title={Building Portable Options: Skill Transfer in Reinforcement Learning.},
  author={Konidaris, George Dimitri and Barto, Andrew G},
  booktitle={Ijcai},
  volume={7},
  pages={895--900},
  year={2007}
}

% LEAP
@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% PRM-RL
@inproceedings{faust2018prm,
  title={Prm-rl: Long-range robotic navigation tasks by combining reinforcement learning and sampling-based planning},
  author={Faust, Aleksandra and Oslund, Kenneth and Ramirez, Oscar and Francis, Anthony and Tapia, Lydia and Fiser, Marek and Davidson, James},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={5113--5120},
  year={2018},
  organization={IEEE}
}

% RL-RRT
@article{chiang2019rl,
  title={RL-RRT: Kinodynamic motion planning via learning reachability estimators from RL policies},
  author={Chiang, Hao-Tien Lewis and Hsu, Jasmine and Fiser, Marek and Tapia, Lydia and Faust, Aleksandra},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={4},
  pages={4298--4305},
  year={2019},
  publisher={IEEE}
}

% PRM
@article{kavraki1996probabilistic,
  title={Probabilistic roadmaps for path planning in high-dimensional configuration spaces},
  author={Kavraki, Lydia E and Svestka, Petr and Latombe, J-C and Overmars, Mark H},
  journal={IEEE transactions on Robotics and Automation},
  volume={12},
  number={4},
  pages={566--580},
  year={1996},
  publisher={IEEE}
}

% RRT

@techreport{lavalle1998rapidly,
  title={Rapidly-exploring random trees: A new tool for path planning},
  author={LaValle, Steven},
  number={98-11},
  year={1998},
  institution={Department of Computer Science, Iowa State University}
}

@article{beker2022palmer,
  title={PALMER: Perception-Action Loop with Memory for Long-Horizon Planning},
  author={Beker, Onur and Mohammadi, Mohammad and Zamir, Amir},
  journal={arXiv preprint arXiv:2212.04581},
  year={2022}
}

@article{ichter2020broadly,
  title={Broadly-exploring, local-policy trees for long-horizon task planning},
  author={Ichter, Brian and Sermanet, Pierre and Lynch, Corey},
  journal={arXiv preprint arXiv:2010.06491},
  year={2020}
}

@inproceedings{van2020mdp,
  title={{MDP} homomorphic networks: Group symmetries in reinforcement learning},
  author={Van der Pol, Elise and Worrall, Daniel and van Hoof, Herke and Oliehoek, Frans and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{mondal2022eqr,
  title={{EqR}: Equivariant representations for data-efficient reinforcement learning},
  author={Mondal, Arnab Kumar and Jain, Vineet and Siddiqi, Kaleem and Ravanbakhsh, Siamak},
  booktitle={International Conference on Machine Learning},
  pages={15908--15926},
  year={2022},
  organization={PMLR}
}

@inproceedings{wang2022so,
  title={SO (2)-Equivariant Reinforcement Learning},
  author={Wang, Dian and Walters, Robin and Platt, Robert},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

% R-Max pour count based
@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  pages={213--231},
  year={2002}
}

% DSG
@inproceedings{bagaria2019option,
  title={Option discovery using deep skill chaining},
  author={Bagaria, Akhil and Konidaris, George},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={3rd International Conference for Learning Representations},
  year={2015}
}

@article{forestier2022intrinsically,
  title={Intrinsically motivated goal exploration processes with automatic curriculum learning},
  author={Forestier, S{\'e}bastien and Portelas, R{\'e}my and Mollard, Yoan and Oudeyer, Pierre-Yves},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={6818--6858},
  year={2022},
  publisher={JMLRORG}
}

@inproceedings{pere2018unsupervised,
  title={Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration},
  author={P{\'e}r{\'e}, Alexandre and Forestier, S{\'e}bastien and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{angelotti2022expert,
  title={Expert-guided Symmetry Detection in Markov Decision Processes},
  author={Angelotti, Giorgio and Drougard, Nicolas and Chanel, Caroline PC},
  booktitle={Proceedings of the 14th International Conference on Agents and Artificial Intelligence},
  year={2022}
}

% Curriculum learning en RL
@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={International conference on Machine Learning},
  pages={41--48},
  year={2009}
}

% RGL
@inproceedings{bonnavaud2023learning,
  title={Learning State Reachability as a Graph in Translation Invariant Goal-based Reinforcement Learning Tasks},
  author={Bonnavaud, Hedwin and Albore, Alexandre and Rachelson, Emmanuel},
  booktitle={$16^{th}$ European Workshop on Reinforcement Learning},
  year={2023},
  address={Bruxelles}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%              ROBOTICS              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Learning to walk in 20 minutes
@inproceedings{tedrake2005learning,
  title={Learning to walk in 20 minutes},
  author={Tedrake, Russ and Zhang, Teresa Weirui and Seung, H Sebastian and others},
  booktitle={Proceedings of the Fourteenth Yale Workshop on Adaptive and Learning Systems},
  volume={95585},
  pages={1939--1412},
  year={2005},
  organization={Beijing}
}

@article{smith2022walk,
  title={A walk in the park: Learning to walk in 20 minutes with model-free reinforcement learning},
  author={Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2208.07860},
  year={2022}
}

@article{ibarz2021train,
  title={How to train your robot with deep reinforcement learning: lessons we have learned},
  author={Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
  journal={The International Journal of Robotics Research},
  volume={40},
  number={4-5},
  pages={698--721},
  year={2021},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{francis2020long,
  title={Long-range indoor navigation with prm-rl},
  author={Francis, Anthony and Faust, Aleksandra and Chiang, Hao-Tien Lewis and Hsu, Jasmine and Kew, J Chase and Fiser, Marek and Lee, Tsang-Wei Edward},
  journal={IEEE Transactions on Robotics},
  volume={36},
  number={4},
  pages={1115--1134},
  year={2020},
  publisher={IEEE}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%            RL + ROBOTICS           %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{carlucho2018adaptive,
  title={Adaptive low-level control of autonomous underwater vehicles using deep reinforcement learning},
  author={Carlucho, Ignacio and De Paula, Mariano and Wang, Sen and Petillot, Yvan and Acosta, Gerardo G},
  journal={Robotics and Autonomous Systems},
  volume={107},
  pages={71--86},
  year={2018},
  publisher={Elsevier}
}

@article{liu2021deep,
  title={Deep reinforcement learning for the control of robotic manipulation: a focussed mini-review},
  author={Liu, Rongrong and Nageotte, Florent and Zanne, Philippe and de Mathelin, Michel and Dresp-Langley, Birgitta},
  journal={Robotics},
  volume={10},
  number={1},
  pages={22},
  year={2021},
  publisher={MDPI}
}

@INPROCEEDINGS{zhao2020simtoreal,
  author={Zhao, Wenshuai and Queralta, Jorge Peña and Westerlund, Tomi},
  booktitle={2020 IEEE Symposium Series on Computational Intelligence (SSCI)},
  title={Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey},
  year={2020},
  volume={},
  number={},
  pages={737-744},
  keywords={Robots;Reinforcement learning;Task analysis;Robot sensing systems;Training;Adaptation models;Optimization;Deep Reinforcement Learning;Robotics;Simto-Real;Transfer Learning;Meta Learning;Domain Randomization;Knowledge Distillation;Imitation Learning},
  doi={10.1109/SSCI47803.2020.9308468}
}

@inproceedings{tobin2017domain,
  title={Domain randomization for transferring deep neural networks from simulation to the real world},
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2017 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={23--30},
  year={2017},
  organization={IEEE}
}

@inproceedings{bousmalis2018using,
  title={Using simulation and domain adaptation to improve efficiency of deep robotic grasping},
  author={Bousmalis, Konstantinos and Irpan, Alex and Wohlhart, Paul and Bai, Yunfei and Kelcey, Matthew and Kalakrishnan, Mrinal and Downs, Laura and Ibarz, Julian and Pastor, Peter and Konolige, Kurt and others},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={4243--4250},
  year={2018},
  organization={IEEE}
}

@inproceedings{higgins2017darla,
  title={Darla: Improving zero-shot transfer in reinforcement learning},
  author={Higgins, Irina and Pal, Arka and Rusu, Andrei and Matthey, Loic and Burgess, Christopher and Pritzel, Alexander and Botvinick, Matthew and Blundell, Charles and Lerchner, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={1480--1490},
  year={2017},
  organization={PMLR}
}

@article{jones2006robots,
  title={Robots at the tipping point: the road to iRobot Roomba},
  author={Jones, Joseph L},
  journal={IEEE Robotics \& Automation Magazine},
  volume={13},
  number={1},
  pages={76--78},
  year={2006},
  publisher={IEEE}
}

@inproceedings{koenig2004design,
  title={Design and use paradigms for gazebo, an open-source multi-robot simulator},
  author={Koenig, Nathan and Howard, Andrew},
  booktitle={2004 IEEE/RSJ international conference on intelligent robots and systems (IROS)(IEEE Cat. No. 04CH37566)},
  volume={3},
  pages={2149--2154},
  year={2004},
  organization={Ieee}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%             CATASTROPHIC FORGETTING              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% ISOLATION METHODS
@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}

@article{fernando2017pathnet,
  title={Pathnet: Evolution channels gradient descent in super neural networks},
  author={Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A and Pritzel, Alexander and Wierstra, Daan},
  journal={arXiv preprint arXiv:1701.08734},
  year={2017}
}

@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018}
}

%%% REGULARISATION METHODS

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@article{chaudhry2018efficient,
  title={Efficient lifelong learning with a-gem},
  author={Chaudhry, Arslan and Ranzato, Marc'Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:1812.00420},
  year={2018}
}


%%% REPETITION METHODS
@article{chaudhry2019tiny,
  title={On tiny episodic memories in continual learning},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip HS and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:1902.10486},
  year={2019}
}

@inproceedings{colas2019curious,
  title={Curious: intrinsically motivated modular multi-goal reinforcement learning},
  author={Colas, C{\'e}dric and Fournier, Pierre and Chetouani, Mohamed and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  booktitle={International conference on machine learning},
  pages={1331--1340},
  year={2019},
  organization={PMLR}
}

% Hedwin's internship (Solve catastrophic forgetting while learning skills sequentially with DIAYN)
@phdthesis{bonnavaud2021apprentissage,
  title={Apprentissage s{\'e}quentiel de comp{\'e}tences via la motivation intrins{\`e}que et l'apprentissage par renforcement},
  author={Bonnavaud, Hedwin and Aubret, Arthur and Matignon, La{\"e}titia},
  year={2021},
  school={Universit{\'e} Lyon 1}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% DIAYN
@article{eysenbach2018diversity,
  title={Diversity is all you need: Learning skills without a reward function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.06070},
  year={2018}
}
